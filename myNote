
异步消息超前问题处理
	1. 使用redis分布式锁
	2. 带状态更新
分阶段缓存存取设计
	1. 对于并发量低&主要是修改请求的积分发放阶段, 使用MySQL数据库.
	2. 对于并发量高&主要是查询请求的奖励发放阶段, 使用Redis缓存&MySQL支撑做防穿透处理的缓存设计.
不停机数据迁移并采用动态数据源拆库
	1. 把用户流量数据和用户返利数据迁移到新库中,
		后台线程不停在跑, 前台查询以老库为准, 修改新增双写.
		然后迁移完毕后查新库, 并把老库操作停止.
	2. 使用AbstractRoutingDataSource数据源路由器, 实现InitializingBean在mapper的beanPropertySet后设置数据源
对接标签用户和各省份用户名单, 自定义的任务完成体系
	1. 任务使用状态模式, 使用dubbo对接其他部门的标签用户, 省份名单.
	2. 使用Kafka对接其他部门, 使用mysql对接业务内的用户任务完成.
异常问题的协查
	1. 用户事务操作联调查询的管理页面, 可以查询用户返利事务中的每一步操作.
定时重试机制
	1. 非即时返利2小时后进行补返利操作, 重试3次进行记录预警.
	2. 即时返利5分钟重试.


领券接口超发问题
	1. 根据业务, 一定比例的请求会有几率失败, 使用请求限制+库存限制;
		请求限制先达到, 返回"活动火爆".
			稍等后库存限制也达到, 已抢完
			如果Kafka返回释放部分请求, 可以接着抢.
			但如果请求限制满, 库存已满95%就"已抢完".
	2. 分段库存设计
	3. 使用队列串行化, 由一台机器操作.
本地缓存解决redis热点数据
	1. redis热点数据, 只读, 可以+随机数备份读取/
	2. springSession, 存储热点数据
分布式锁防止用户任务重复
	zk分布式锁
	redis锁: redis中基于cas的乐观锁, 自写Lua脚本
令牌桶限流+dubbo+线程池限制+项目拆分避免对其他线上业务影响
	1. guava令牌桶, 每台服务器每秒放出100个令牌
	2. dubbo线程池, 限制业务500个
	3. 拆分出抢购业务.


扣款流程设计
	1. 同步请求-发送Kafka消息, 为用户发送短信
	2. 监听用户上行短信topic, 根据消息-发送Kafka消息扣款操作
					回调省公司
	3. 监听Kafka消息, 扣款中间-回调省公司, 并确认
			最终扣款成功-回调省公司.
流水对账工作
	定时任务每月整理跑出账单数据, 异常数据的异常表-责任人记录.


每月亿条流量数据处理入库
	1. 月初定时任务跑多省数据,
	2. 1000条并发跑.
异常数据的处理, 防止自损.
分省限制规则
	1. 使用适配器和代理模式指定每个省份的用户条件.


随着红包项目的扩张, 开始对项目进行优化与分割
	1. 先把领券中心分出去
	2. 定时任务
	3. 批量数据
由 redis 主从哨兵模式切换 redisCluster,
Apollo 自动化配置整合,
小组开发日志整理与总结等.

消息积压与未消费情况的处理
	移动consumer在zk的offset, 实现重复消费

内存泄漏 OOM 问题排查
	4. OOM事件:
                1. Quartz定时任务内存泄漏: The web application [/project] appears to have started a thread named [SchedulerFactoryBean-Worker-1] but has faild to stop it
                        原因: 系统在关闭时没有给Quartz时间来停止它所创建的定时任务，导致线程未被停止系统便已经关闭了。
                        解决: 配置QuartzContextListener实现ServletContextListener，并在ContextDestroyed时执行SchedulerFactoryBean的shutdown方法
                2. HTTP线程未关闭异常:
                        原因: httpAsyncClient客户端在请求失败的情况下，httpclient.close()此处会导致主线程阻塞，
                                经源码发现close方法内部，在线程连接池关闭以后,
                                httpAsyncClient对应线程还处于运行之中，一直阻塞在epollWait
                3. 创建超大数组:
                        原因: 定时任务项目跑数据, OOM
                        解决: JVM调整新生代大小-Xmx, 并增加编码规则.
