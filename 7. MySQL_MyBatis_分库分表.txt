
MySQL:
	todo http://blog.codinglabs.org/articles/theory-of-mysql-index.html

	存储引擎MyISAM与InnoDB的理解: show engines;show variables like '%storage_engine%';
		1. MyISAM: 性能极佳, 适合读密集情况.
			存储: 索引文件与数据文件隔开, 索引直接存放数据地址. 无法安全恢复.
			索引: B+树, 不支持外键
			锁: 表锁, 不支持事务.
		2. InnoDB: 支持事务, 行级锁, 支持外键, 支持MVCC(读提交和可重复读级别).
			存储: 聚簇索引, B+树.在用到聚簇索引和需要访问的数据可以放内存的时候, innoDB非常快.
			索引: B+树
			锁: 行锁, 支持事务. 没有索引也会锁表
	存储结构/基本存储结构: 基本存储结构是页.
		1. 所有数据都存储到了表空间中. 表空间依次由:段(segment)->区(extent)->页(page)组成.
		2. 段有索引段: 非叶子节点, 数据段: 叶子节点. 回滚段
		3. 区: 64个连续的页组成, 16*64=1mb,
		4. 页是数据库管理磁盘的最小单位, 整页读入内存(一下子读多个磁盘块).
		5. 每个页16kb, 包含fileHeader(38字节), pageHeader(56字节), infimum+supermum(26字节), userRecord, freeSpace, pageDirectory, failTailer(8字节)
			数据页, undo页, 系统页, 事务数据页....
		6. 所有的数据页可以组成一个双向链表, 数据页内的记录组成单向链表.
			据页都会为存储在它里边儿的记录生成一个页目录, 为主键二分法定位记录, 其他列要遍历查找.
	字符集和校对规则: 字符集指的是一种从二进制编码到某类字符符号的映射, 校对规则则是指某种字符集下的排序规则.
	InnoDB后台线程: https://blog.51cto.com/lijianjun/1945517
		4个IO thread, 1个master thread, 1个锁监控线程, 1个错误监控线程.
		1. Master Thread:核心后台线程, 负责把缓冲池中的数据异步刷新到磁盘中, 包括脏页的刷新, 合并插入缓冲, undo页的回收等.
			大部分操作, 由每1s操作和每10s操作.
		2. IO Thread: 处理IO请求的
	InnoDB内存模型: 
		1. 重做日志缓冲: 重要日志信息先放入, 刷新到重做日志文件中. redoLog
		2. 额外内存池: 每个缓冲池的帧缓冲和对应的缓冲对象(记录LRU,锁等信息) 在额外内存池中申请,
		3. 缓冲池: 缓冲池是占最大的内存部分.  按照LRU(least recent used, 最近最少使用) 算法保留缓存页.
			*修改*:修改的时候首先修改缓冲池中的页, 然后按照一定频率把修改后的脏页刷新到文件.
			包括索引页, 数据页, undo页, 插入缓冲(insert buffer)等
	InnoDB关键特性:
		1. 插入缓存: 辅助索引且不唯一的索引使用. 非聚集索引的叶子接地点插入无序问题
			1. 如果该索引页在缓冲池中，直接插入
			2. 否则，先将其放入插入缓冲区中，再以一定的频率和索引页合并
		2. 两次写(double write): 防止正在写数据页时候宕机丢失部分数据, redoLog只记录对页的物理修改, 无法恢复.
			解决: 在redoLog之前先弄一个原始页的副本, 内存两次写缓冲(2MB), 磁盘共享表空间128页(2M)
				如果宕机没有可以从磁盘共享表空间中恢复.
			1. 刷脏页时先拷贝到内存的两次写缓冲中
			2. 两次写缓存中的数据分两次写入共享表空间中(每次1M)
			3. 从两次写缓冲区写入数据文件中.
		3. 自适应哈希索引(adaptiveHashIndex):
			监控对表上二级索引的查找，如果发现某二级索引被频繁访问，二级索引成为热数据，建立哈希索引可以带来速度的提升
	日志:
		1. binLog:
			基于行格式的逻辑日志, 是逻辑的SQL.
			二进制日志记录了数据库更改的所有操作, **不包括select/show操作.**
		2. redoLog:
			物理日志，记录数据库中每个页的修改.
			默认有ib_logfile0和ib_logfile1两个文件, 是innoDB引擎的重做日志文件. **记录了InnoDB引擎的事务日志.**
		3. undoLog: 提供回滚和多个行版本控制(MVCC)
			逻辑日志, 数据修改的时候，不仅记录了redo，还记录了相对应的undo.
			可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然

	一条sql语句在mysql中如何执行的:
                server层: 实现跨存储引擎的功能
                        1. 连接器： 身份认证和权限相关(登录 MySQL 的时候)。
                        2. 查询缓存: 执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除）。
                        3. 分析器: 没有命中缓存的话，分析器先词法分析看SQL语句要干嘛，再语法分析检查SQL语句语法是否正确。
                        4. 优化器: 按照 MySQL 认为最优的方案去执行。多个索引的时候该如何选择索引，多表查询的时候如何选择关联顺序等。
                        5. 执行器: 首先执行前会校验该用户权限，然后从存储引擎返回数据。
                        6. 日志模块（binlog）, innoDB多一个自己的redoLog.
                存储引擎: 负责数据的存储与读取
                更新语句:
                        1. 先查到数据, 如果缓存有也开启了, 那就用缓存;
                        2. 调用引擎 API 接口，写入更改的数据并保存在内存里,写入redoLog.
                                 redo log 进入 prepare 状态，然后告诉执行器，执行完成了，随时可以提交。
                        3. 执行器收到通知后记录 binlog，然后调用引擎接口，提交 redo log 为提交状态。
                        4. 完成.
                记录两个日志模块:
                        最初InnoDB引擎是以插件形式插入MySQL的. redoLog是InnoDB引擎特有的保证crash-safe.
                        redoLog要引入prepare预提交状态:
                                如果:    1. redoLog先提交再写binLog, 中间机器挂了binLog没有被写入, binLog备份主从会丢失.
                                        2. 先写入binLog然后写redoLog, 中间挂掉恢复的时候本机无法恢复这一条数据.
                                引入prepare后, 如果恢复时候redoLog是prepare, 就去判断binLog是否完整.
        	查询优化:
        		1. 带索引限定数据范围, 禁止不带任何限制数据范围条件的查询语句
        		2. 读写分离
        		3. 垂直分区, 虽然会有冗余和join操作, 但会使列数据变小, 查询时减少读取的Block数, 减少I/O次数
        		4. 严禁左模糊或全模糊查询.
        		5. 不得使用外键与级联，一切外键概念必须在应用层解决。
        		6. 禁止在表中建立预留字段

	数据库索引: 
		实现: 将无序的数据变成有序(相对) 
			https://camo.githubusercontent.com/c63688b141c3562bbf4fb4b719ab027c6dea91e9/687474703a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f31382d31302d322f38393333383034372e6a7067
		hash索引: 单条记录查询时, 最快. innodb不支持, 只支持自适应hash
		BTree索引: B+Tree, 
			MyISAM: B+Tree叶节点的data域存放的是数据记录的地址。以 data 域的值为地址读取相应的数据记录, 这是非聚簇索引.
			InnoDB: 其数据文件本身就是索引文件。其表数据文件本身就是按B+Tree组织的一个索引结构，叶节点data域保存了完整的数据记录.
				根据主索引搜索, 直接找到key所在的节点即可取出数据;
				不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。
		组合索引: 
		覆盖索引: 不需要回表的索引, 可以是组合索引和单列索引.
		最佳实践:使用索引注意事项: 
			1. 使用在where上筛选的字段, 需要排序的字段, 不要用函数.
			2. 使用业务无关的自增主键(逻辑主键), 不用业务主键.
			3. 索引列设为notNull, 否则优化会放弃索引.
			4. 删除长期未用的索引.
		从底层解释最左匹配原则:
			索引底层是B+树, 联合索引(a,b)也是B+树. 联合索引的a是有顺序的, B的顺序在同一个a也是有顺序的. 所以最左有顺序, 次左顺序是相对的
		数据库的索引有哪几种: todo ?????
		组合索引和几个单个的索引有什么区别:
		数据库的大表查询优化了解吗？
			1. 语法优化, 使用索引, 避免使用<>范围查询
			2. 增加过滤条件
			3. 建立中间表
	mysql慢语句调优做过吗？说说你是怎么做的？
		1. explain+sql查看现在查询的问题
		2. 添加限定条件, 命中索引.
		3. 优化索引.



	查询缓存:执行查询语句的时候, 会先查询缓存. MySQL8.0版本后移除. query_cache_type=1
		开启查询缓存后在同样的查询条件以及数据情况下, 会直接在缓存中返回结果.
		表(数据或结构)发生变化, 那么和这张表相关的所有缓存数据都将失效.
		带来了额外的开销, 每次查询后都要做一次缓存操作, 失效后还要销毁.

	事务:
		四大特性: A(atomicity)C(consistency)I(isolation)D(Durability) 原子性, 一致性, 隔离性, 持久性.
		并发事务带来的问题:
			1. 脏读: 读到了其他事务未提交的数据
			2. 丢失修改: A事务修改了数据, 但提交后发现保留的是B修改后的数据. 需要让事务在共同操作同一行的时候串行化. For Update.
			3. 不可重复读: 在同一事务内多次读取统一数据, 结果不一样. MVCC.
			4. 幻读: 在同一事务内, 多次读取几行数据, 结果发现多了数据/少了数据. lock锁 区间锁
			不可重复读的重点是数据被修改, 幻读的重点在于新增或者删除
		事务隔离级别:
			1. read-uncommitted: 读未提交, 会有脏读.
			2. read-committed: 读提交, 解决了脏读.
			3. repeatable-read: 可重复读, 解决了不可重复读. 默认. InnoDB+Next-KeyLock可以解决幻读.
				可重复读怎么实现的，怎么定位到哪一行: todo
			4. Serializable: 串行化, 都解决了.

	锁: https://blog.csdn.net/eygle/article/details/96835813
		MyISAM与InnoDB引擎所使用: MyISAM采用表级锁, InnoDB支持行级锁(row-level locking)和表级锁,默认为行级锁, InnDB行锁是锁索引上的索引项
		共享锁&排他锁:
			共享锁: 读锁, 事务T对数据A加上共享锁, 其他事务只能对A再加共享锁.
				SELECT ...LOCK IN SHARE MODE;
			排他锁: 写锁, 事务T对数据A加上排他锁, 其他事务不能对A加任何锁.
				SELECT ...FOR UPDATE;
				自增长锁: 插入操作, 会根据自增长器的值+1 再赋值. 称为auto-inc lockng, 特殊的表锁机制. 锁再完成子增长值插入sql后立即释放. 默认使用互斥量(mutex)堆计数器累加.
		InnoDB的两个意向表级锁: 一个事务在获取资源锁的时候，如果资源已经被排他锁占用的时候，可以在表上加一个意向锁.
			意向共享锁(IS): 事务准备给数据行记入共享锁, 事务在一个数据行加共享锁前必须先取得该表的IS锁。
			意向排他锁(IX): 事务准备给数据行加入排他锁, 事务在一个数据行加排他锁前必须先取得该表的IX锁。
			IS是表级锁，不会和行级的X，S锁发生冲突，只会和表级的X，S发生冲突。
		InnoDB的锁算法:
			RecordLock: 单个行记录上的锁.
			GapLock: 间隙锁, 锁定一个范围(,)开区间. 防止多个事务插同意区间.
			Next-keyLock: record+gap, 锁定一个范围, [,) 闭区间. 为了解决幻读. 
				行查询也使用.如果行查询的索引有唯一属性, 降级未recordLock.
				select..for update 会索引的上一个&下一个的区间加锁. 
		mvcc(多版本并发控制): 实现一致性非锁定读. 可以保证readCommited到readRepeat
			1. 该行之前版本的快照数据通过undo段实现.
			2. 如果读取的是被X锁住的行(排他锁), 会读取行的快照数据.
		MVCC机制了解不？
                        SELECT操作可以不加锁而是通过MVCC机制读取指定的版本历史记录
                        todo https://www.codercto.com/a/88775.html
                        是通过在每行记录后面保存两个隐藏的列来实现的,这两个列，分别保存了这个行的创建时间，一个保存的是行的删除时间. 时间是事务ID而不是具体时间.
                        MVCC机制有什么问题？怎么去解决这个问题？
                                每行记录都需要额外的存储空间，需要做更多的行维护和检查工作。
		死锁: InnoDB的行级锁是对索引加的锁，如果查询语句为命中任何索引，那么InnoDB会使用表级锁.
			不同于MyISAM总是一次性获得所需的全部锁，InnoDB的锁是逐步获得的，当两个事务都需要获得对方持有的锁，导致双方都在等待，这就产生了死锁。 
		mysql解决死锁机制:
			死锁后，InnoDB一般都可以检测到，并使一个事务释放锁回退，另一个则可以获取锁完成事务.
			1. 事务回滚.
			2. 设置超时时间.
			3. wait-for graph (等待图) 进行死锁检测, 主动检查锁的信息链表, 事务等待链表: 不能有回路.
			4, 通过表级锁可以减少死锁.
			5. 多个程序尽量按照相同的顺序访问表.
			6. 同一事物尽可能一次性锁定所需要的资源.
		锁级别, 什么情况下会发生:
		        表锁: 成功使用索引时锁行，否则锁表
		        区间锁: 事务中的索引排他锁
		        行锁: 锁索引
			页锁: InnoDB不支持页锁
		谈谈数据库乐观锁与悲观锁:
			乐观锁: 使用version字段, 每次更新校验.
			乐观锁如何保证线程安全:
			悲观锁: forUpdate, 每次查询加悲观锁.


	mysql join的底层原理是什么

	系统的MySQL并发: 2000? top:5000?
	MyISAM与InnoDB的理解: 聚簇索引/非聚簇索引
	主键与性能:
		为什么是B+而不是B或hash
		B+树非叶子节点只存索引, 更小可以放在内存, IO也会少.
		B+树叶子节点的链表操作很好.
	数据库索引，底层是怎样实现的，为什么要用B树索引？
                1. 红黑树往往出现由于树的深度过大而造成磁盘IO读写过于频繁
                2. BTree的非叶子节点也存数据, 也会增加IO数.
	慢sql是哪条???
		慢sql日志可以设置.
	explain 可以看到哪些信息, 结果列是什么:???
		1. id: 执行计划id, id越大越先开始. 子查询与父是两个执行计划
		2. select_type: 查询类型: simple普通查询, primary 查询中包含子部分, 最外层查询就是, subquery select/where有子查询, DERIVED:from有子查询,
				union, unionResult.
		3. table: 表
		4. type: system 表只有一行数据> const 通过索引一次就找到> eq_ref 唯一性索引扫描> ref 非唯一的索引> range 扫描范围索引> index (Full Index Scan)扫全部索引> all 全表扫
		5. possible_keys和key: 可能应用和实际使用的索引
		6. key_len: key_len显示的值为索引字段的最大可能长度，并非实际使用长度.
		7. ref: 显示索引的哪一列被使用.
		8. rows: 大概需要读取的行数.
		9. Extra: 额外信息.
	当前项目的mysql架构:
		三个数据源, 三个主从.
		spring的RoutingDataSource进行切换数据源
		sharding-jdbc进行分表.
	读写分离: 使用主从复制架构
	读写分离你是怎么实现的:
	主从复制: 
		原理: 主库将变更写binlog日志，然后从库连接到主库之后，从库有一个IO线程，将主库的binlog日志拷贝到relayLog，
			写入一个中继日志中,接着从库中有一个SQL线程会从中继日志读取binlog，然后执行binlog日志中的内容
		延时: 几十-几百毫秒.
		半同步复制: 解决从库数据丢失问题, 主库写binlog时候, 会强制把数据同步到从库的relayLog, 收到从库的ack确认后才会任务写操作完成.
		并行复制: 解决主从同步延时, 从库开启多线程, 并行读取relayLog日志.
	mysql主从同步延时问题:
		对于需要强同步的, 就用半同步复制.
		不建议刚插入, 立马查询更改. 失去了主从的意义.	
	MySQL数据库容灾备份方案:
		1. 主从数据库.
		2. 从库定时冷备份.
	Mysql对联合索引有优化么？会自动调整顺序么？哪个版本开始优化？
		命名规则：表名_字段名
		1、需要加索引的字段，要在where条件中
		2、数据量少的字段不需要加索引
		3、如果where条件中是OR关系, 加索引不起作用
		4、符合最左原则
	索引查询优化: TODO
		1. 尽量不要用or，如果可以用union代替
		2. 不要用IN
		3. 使用explain查看.
		4. 使用联合索引避免回表
		5. 使用limit时候先查ID, 避免多次回表
	什么是区分度比较高的索引:?????
		区别度能达到0.1,索引的性能就可以接受
		select count(distinct left(xrow, 10)) from table1

	内连接、外连接、左(外)连接、右(外)连接、全连接:


SQL优化，常用的索引？



MyBatis: https://mp.weixin.qq.com/s?__biz=MzUzMTA2NTU2Ng==&mid=2247488132&idx=3&sn=da485b7e53fc1a95acad6baf06892591&scene=21#wechat_redirect
	Mybatis是什么框架: 半ORM（对象关系映射）框架，它内部封装了JDBC
		MyBatis二级缓存的工作流程和前文提到的一级缓存类似，只是在一级缓存处理前，用CachingExecutor装饰了BaseExecutor的子类，在委托具体职责给delegate之前，实现了二级缓存的查询和写入功能，具体类关系图如下图所示。
	MyBatis特点:
		1. 分离sql和业务代码, 把SQL语句放在XML配置文件
		2. 解除SQL与程序代码的耦合, 通过DAO层, 将业务逻辑和数据逻辑分离, 更易单元测试.
		3. 简单和轻量化, 无第三方依赖.
	整体架构:
		1. 接口层: Mapper/Dao接口中的接口定义.
			增删改查, 获取配置接口
			SqlSessionFactory, SqlSession是最重要的接口.
		2. 数据处理层: Mapper->xml层次之间
			参数映射, SQL解析, , 结果映射.
			配置解析:
			SQL解析和scripting模块:
			SQL执行: 设计多个组件, 包含四大核心: Executor,StatementHandler,ParamenterHandler,ResultSetHandler.

		3. 基础支持层: 支撑上面两个.
			连接管理
			事务管理
			配置加载
			缓存处理
Sharding-JDBC:
	分库分表最佳实践: SQL解析，重写，路由，执行，结果归并
	分库分表: 
		分库分表原理:
		数据库中间件比较:
			client:
				sharding-jdbc:
			proxy: 
				atlas: 
				cobar: 
				TDDL: 
				mycat: 
		项目中是怎么进行分库分表的:
			垂直拆分: 
				拆多张表:
				不同表到多个库:
			水平拆分: 
		分表方法:
			range: 简单, 扩容好, 但是热点数据还是查最新表.
			hash: 平均, 但是扩容数据迁移麻烦.
		迁移数据:
			1. 停机迁移: 应用停机, 部署多线程开始跑数据
			2. 双写迁移方案: 
				对老库操作, 同时加上对新库的操作
				后台跑导数据工作. 把老库导入新库, 如果新库没有直接插入, 否则对比更新时间插入.
		动态扩容缩容:
			1. 停机扩容: 停机, 然后并行跑数据, 上亿数据量大概跑2-3小时.
			2. 直接迁移库: 可以多建一些逻辑库在同一个数据库上, 拆分时候在库和mysql服务器做配置就好. 服务器成倍扩容.
		全局ID:
			如何实现唯一ID: ??
			1. 数据库自增id: 使用一个表, 每次插入一条拿到一个id. 高并发很慢.
			2. UUID: 本地生成, 但是太长了, 做主键性能差.
			3. 当前系统时间拼接: 当前系统时间加上其他的业务(手机号等), 做唯一ID.
			4. snowflake算法: 64位ID, 1bit为0(正数), 41bit做毫秒数,10bit做工作机器id, 12bit做序列号.
				snowflake算法问题: ???
			5. 利用redis生成id: redisAtomicLong.incrementAndGet
			6. 美团leaf分布式ID: https://tech.meituan.com/2017/04/21/mt-leaf.html
				https://www.cnblogs.com/huangying2124/p/11736031.html
		做了分表没有做分库原因:

		
使用场景及限制: 
业务增加了只增加服务器不拆分可以吗? MySQL只换高性能的服务器可以吗?
	不可以, 硬盘IO限制.

数据库性能调优如何做:
	1. 硬件能力: CPU,内存,IO
	2. 操作系统版本和参数
	3. 数据量, 并发用户
	4. 索引, 隐式转换, 数据类型, 统计信息, 自动增长
	5. 单数据库设计, OLTP(修改)/OLAP(查询)操作
	6. 主键, OR/LIKE, 表结构等等


查询中哪些情况不会使用索引？
	1. 全表扫更快
	2. OR分割左右条件, 如果只有一个条件有索引, 那么不会走
	3. 条件不是复合索引的第一部分, 部门组最左前缀
	4. LIKE 不能左模糊
	5. string加引号, 避免隐式转换
	6. in 后面的条件不超过一定数量仍然会使用索引






从千万的数据到亿级的数据, 会面临哪些技术挑战?你的技术解决思路?
	1. 业务拆分, 库拆分
	2. 同步转异步
	3. 分片, 写查分离.

对分布式架构设计的哪些方面比较熟悉?


大数据存储；


MYSQL 数据表在什么情况下容易损坏?
	1. mysqld 进程在写表时被杀掉
	2. 宕机
	3. 损坏症状: sql执行不了. 打不开表


数据库索引了解吗?


Mysql如何为表字段添加索引?
	alter table `table_name` add primary key(`column`);
	alter table `table_name` add index index_name(`column1`,`column2`,`column3`);


对于大表的常见优化手段说一下
	1. 读写分离, 分区
	2. 索引限定数据的范围

mysql 里记录货币用什么字段类型好

当MySQL单表记录数过大时，数据库的CRUD性能会明显下降，有哪些常见的优化措施？




